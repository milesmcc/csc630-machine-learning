{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 3 — Reference Notebook\n",
    "\n",
    "This is Miles' reference notebook for test #3 in CSC630 Machine Learning.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boilerplate Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common Import Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading basic CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dataframe from raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                  2d array                  labels\n",
    "hd = pd.DataFrame(raw_dataset.data, columns=raw_dataset['feature_names'])\n",
    "hd['...'] = raw_dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df.shape` provides (samples, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first real look, always call `df.head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df.describe()` is also very helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful—but obtuse—data cleaning feature is `df.dropna()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, column names are prepended with whitespace due to an incorrect CSV read. If that's the case, this one-liner can help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={column: column.strip() for column in df.columns}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting allows simple feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mpg_reciprocal'] = df['mpg'] ** -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Horizontal slicing allows the creation of sub-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sliced = df[df[\"...\"] == \"...\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns can be dropped, too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"column name\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(start, stop, step) # includes start, excluses stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.sample(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "\n",
    "Remember that `matplotlib.pyplot` plots can be overlayed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to always add a colorbar (if applicable), label axes, and name the plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.colorbar()\n",
    "plt.title(\"PCA transformations and error of a multiclass \\nlogistic regression on the sepal dataset\")\n",
    "plt.xlabel(\"X label\")\n",
    "plt.ylabel(\"Y label\")\n",
    "# plt.xlim(left, right)\n",
    "# plt.ylim(left, right)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic scatterplots, histograms, and line plots (respectively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, Y, c=optional_color_variable, marker='*', alpha=0.2, cmap=\"brg\", s=30)\n",
    "plt.hist(X, bins=[1,2,3])\n",
    "plt.plot(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *emperor of all plots*, however, is the Seaborn pairplot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful; can sometimes take a long time to run!\n",
    "sns.pairplot(df)\n",
    "\n",
    "# Alternatively, if you only need one or two Y values:\n",
    "sns.pairplot(df, y_vars=['MEDV'], x_vars=[key for key in df.keys() if key not in [\"MEDV\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always start with a nice test-train split!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(\"...\"), df[\"...\"], test_size=0.25) # will remove the target column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check accuracy on a **logistic regression**, use the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_true, y_pred)\n",
    "accuracy_score(y_true, [round(model.predict(i)) for i in np.arange(0, 10, 10./200)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check accuracy on a **linear regression**, use the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_squared_error(y_true, y_pred)\n",
    "# or, better:\n",
    "metrics.r2_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform simple one-hot encoding, use the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies = pd.get_dummies(df[['...']], prefix=[\"descriptor\"])\n",
    "df = pd.concat([df, df_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame `.apply(function)` runs the given function for each row in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply a function to only one element, use `.map()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"...\"].map(function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "model.predict(X) # --> y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "model.predict(X) # --> y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dr. Z's Magic Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thank you, Dr. Z!\n",
    "\n",
    "def scatter_with_decision(original_x, original_y, original_z, model, rules=None):\n",
    "    \"\"\" Create a scatter plot for 2-dimensional input data, as well as the decision \n",
    "    boundary for the given logistic regression model. \n",
    "    \n",
    "    parameters:\n",
    "        original_x, original_y, original_z: numpy arrays\n",
    "            the data for the two input dimensions (x and y) and output (z, with values 0 or 1)\n",
    "        model: sklearn.linear_model.LogisticRegression\n",
    "            the already-fit model\n",
    "        rules: List[(index, function)]\n",
    "            A collection of functions defining how to turn the original \n",
    "            columns into your engineered columns.  The index is either `0` or `1` \n",
    "            to indicate that the rule is applied to column 0 or 1, or `2` if \n",
    "            the rule uses both columns.\n",
    "            Some examples:\n",
    "                if you want `original_x**2`, your `rules` should contain the tuple `(0, lambda x: x**2)`.  \n",
    "                if you want `original_y**3`, your `rules` should contain the tuple `(1, lambda x: x**3)`.\n",
    "                if you want `original_x * original_y`, your `rules` should contain the tuple `(2, lambda x, y: x*y)`.\n",
    "    returns:\n",
    "        the Figure and Axes objects produced (in order to add more to it if you want, \n",
    "            e.g. title and axis labels)\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    ### create the decision surface\n",
    "    x = np.arange(original_x.min(), original_x.max(), 0.1)\n",
    "    y = np.arange(original_y.min(), original_y.max(), 0.1)\n",
    "    xx, yy = np.meshgrid(x, y)                       # this is its xy-coordinate grid\n",
    "\n",
    "    ### We need to \"ravel\" the grid's matrices to make them one long column\n",
    "    grid_as_columns =[xx.ravel(), yy.ravel()]\n",
    "    if rules:\n",
    "        for i, rule in rules:\n",
    "            if i < 2:\n",
    "                # this rule uses only one input column\n",
    "                grid_as_columns.append(rule(grid_as_columns[i]))    \n",
    "            else:\n",
    "                # this rule uses both input columns\n",
    "                grid_as_columns.append(rule(grid_as_columns[0], grid_as_columns[1]))\n",
    "    dataset_cols = np.array(grid_as_columns).T       # now we have all the points in the grid as a long (_)x2 array \n",
    "\n",
    "    ### Now we can feed them into the prediction function and reshape it back to the grid\n",
    "    zz_col = model.predict_proba(dataset_cols).T[0]\n",
    "    zz = zz_col.reshape(xx.shape)                    # finally, we have the z-coordinates for each grid point\n",
    "\n",
    "    # make the plots\n",
    "    ax.contour(xx, yy, zz, levels=[.5], colors=['c'])\n",
    "    ax.scatter(original_x, original_y, c=original_z)\n",
    "    return fig, ax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
